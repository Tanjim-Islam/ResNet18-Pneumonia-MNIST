{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist.dataset import PneumoniaMNIST\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\tanji\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\tanji\\.medmnist\\pneumoniamnist.npz\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "full_train_dataset = PneumoniaMNIST(split='train', transform=transform, download=True)\n",
    "\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = PneumoniaMNIST(split='test', transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).squeeze().long()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # print(f\"Predicted: {predicted[:5]}\")\n",
    "            # print(f\"Labels: {labels[:5]}\")\n",
    "            # print(f\"Batch Correct: {(predicted == labels).sum().item()}\")\n",
    "            # print(f\"Batch Total: {labels.size(0)}\")\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "num_classes = len(INFO['pneumoniamnist']['label'])\n",
    "model = ResNet18(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.2449, Train Accuracy: 95.43%, Val Accuracy: 94.59%\n",
      "Epoch [2/30], Loss: 0.1398, Train Accuracy: 97.27%, Val Accuracy: 96.60%\n",
      "Epoch [3/30], Loss: 0.0867, Train Accuracy: 93.10%, Val Accuracy: 93.21%\n",
      "Epoch [4/30], Loss: 0.0871, Train Accuracy: 95.57%, Val Accuracy: 94.27%\n",
      "Epoch [5/30], Loss: 0.0736, Train Accuracy: 97.29%, Val Accuracy: 96.18%\n",
      "Epoch [6/30], Loss: 0.0597, Train Accuracy: 96.31%, Val Accuracy: 94.69%\n",
      "Epoch [7/30], Loss: 0.0528, Train Accuracy: 97.34%, Val Accuracy: 95.33%\n",
      "Epoch [8/30], Loss: 0.0545, Train Accuracy: 97.24%, Val Accuracy: 95.97%\n",
      "Epoch [9/30], Loss: 0.0743, Train Accuracy: 97.72%, Val Accuracy: 96.07%\n",
      "Epoch [10/30], Loss: 0.0496, Train Accuracy: 97.16%, Val Accuracy: 93.84%\n",
      "Epoch [11/30], Loss: 0.0415, Train Accuracy: 98.06%, Val Accuracy: 95.22%\n",
      "Epoch [12/30], Loss: 0.0350, Train Accuracy: 99.39%, Val Accuracy: 97.13%\n",
      "Epoch [13/30], Loss: 0.0317, Train Accuracy: 95.83%, Val Accuracy: 94.37%\n",
      "Epoch [14/30], Loss: 0.0306, Train Accuracy: 98.91%, Val Accuracy: 96.82%\n",
      "Epoch [15/30], Loss: 0.0317, Train Accuracy: 99.04%, Val Accuracy: 96.18%\n",
      "Epoch [16/30], Loss: 0.0224, Train Accuracy: 99.02%, Val Accuracy: 96.60%\n",
      "Epoch [17/30], Loss: 0.0498, Train Accuracy: 96.57%, Val Accuracy: 95.44%\n",
      "Epoch [18/30], Loss: 0.0266, Train Accuracy: 99.50%, Val Accuracy: 96.50%\n",
      "Epoch [19/30], Loss: 0.0130, Train Accuracy: 95.72%, Val Accuracy: 93.95%\n",
      "Epoch [20/30], Loss: 0.0493, Train Accuracy: 99.04%, Val Accuracy: 96.07%\n",
      "Epoch [21/30], Loss: 0.0154, Train Accuracy: 99.73%, Val Accuracy: 96.50%\n",
      "Epoch [22/30], Loss: 0.0128, Train Accuracy: 99.71%, Val Accuracy: 96.71%\n",
      "Epoch [23/30], Loss: 0.0050, Train Accuracy: 99.87%, Val Accuracy: 97.24%\n",
      "Epoch [24/30], Loss: 0.0147, Train Accuracy: 98.75%, Val Accuracy: 95.22%\n",
      "Epoch [25/30], Loss: 0.0249, Train Accuracy: 99.84%, Val Accuracy: 96.92%\n",
      "Epoch [26/30], Loss: 0.0155, Train Accuracy: 98.59%, Val Accuracy: 96.82%\n",
      "Epoch [27/30], Loss: 0.0163, Train Accuracy: 99.23%, Val Accuracy: 95.86%\n",
      "Epoch [28/30], Loss: 0.0099, Train Accuracy: 99.92%, Val Accuracy: 96.50%\n",
      "Epoch [29/30], Loss: 0.0104, Train Accuracy: 99.65%, Val Accuracy: 95.33%\n",
      "Epoch [30/30], Loss: 0.0159, Train Accuracy: 99.79%, Val Accuracy: 96.82%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).squeeze().long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_accuracy = calculate_accuracy(train_loader, model)\n",
    "        val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 85.90%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    test_accuracy = calculate_accuracy(test_loader, model)\n",
    "    print(f'Accuracy of the model on the test images: {test_accuracy:.2f}%')\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet18_pneumonia_mnist.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
